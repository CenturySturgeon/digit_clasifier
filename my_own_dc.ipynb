{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb1712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4b759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c9df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40a1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094b7b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('../../.fastai/data/mnist_png/testing/5'),\n",
       " Path('../../.fastai/data/mnist_png/testing/3'),\n",
       " Path('../../.fastai/data/mnist_png/testing/7'),\n",
       " Path('../../.fastai/data/mnist_png/testing/4'),\n",
       " Path('../../.fastai/data/mnist_png/testing/2'),\n",
       " Path('../../.fastai/data/mnist_png/testing/1'),\n",
       " Path('../../.fastai/data/mnist_png/testing/9'),\n",
       " Path('../../.fastai/data/mnist_png/testing/0'),\n",
       " Path('../../.fastai/data/mnist_png/testing/8'),\n",
       " Path('../../.fastai/data/mnist_png/testing/6')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_folder = Path('../../.fastai/data/mnist_png/testing')\n",
    "training_folder = Path('../../.fastai/data/mnist_png/training')\n",
    "\n",
    "[x for x in testing_folder.iterdir() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "331fd357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Path('../../.fastai/data/mnist_png/training/0'),\n",
       " Path('../../.fastai/data/mnist_png/testing/3'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_testing_folder = testing_folder.ls().sorted()\n",
    "sorted_training_folder = training_folder.ls().sorted()\n",
    "\n",
    "sorted_training_folder[0], sorted_testing_folder[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3537f2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]),\n",
       " torch.Size([6265, 28, 28]),\n",
       " torch.Size([12396, 784]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes_tensors = [tensor(Image.open(o)) for o in (training_folder/'3').ls().sorted()]\n",
    "stacked_threes = torch.stack(threes_tensors).float()/255\n",
    "\n",
    "sevens_tensors = [tensor(Image.open(o)) for o in (training_folder/'7').ls().sorted()]\n",
    "stacked_sevens = torch.stack(sevens_tensors).float()/255\n",
    "\n",
    "#reshape the tensors and concatenate them in a new one\n",
    "test_tensor = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "\n",
    "stacked_threes.shape, stacked_sevens.shape, test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4ff196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_tensors(path_to_images):\n",
    "    \"\"\"A function that returns a stacked Gray Scaled tensor\"\"\"\n",
    "    tensors = [tensor(Image.open(o)) for o in (path_to_images).ls().sorted()]\n",
    "    stacked_tensors = torch.stack(tensors).float()/255\n",
    "    return stacked_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9347be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6131, 28, 28]), torch.Size([6265, 28, 28]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the function works as expected\n",
    "training_stacked_threes = stacked_tensors(sorted_training_folder[3])\n",
    "training_stacked_sevens = stacked_tensors(sorted_training_folder[7])\n",
    "\n",
    "training_stacked_threes.shape, training_stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3866075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensors are equal.\n"
     ]
    }
   ],
   "source": [
    "#Corroborate equality of stacked tensors\n",
    "if torch.equal(stacked_threes, training_stacked_threes) and torch.equal(stacked_sevens, training_stacked_sevens) :\n",
    "    print(\"The tensors are equal.\")\n",
    "else:\n",
    "    print(\"The tensors are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a60e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_tensors(list_of_paths):\n",
    "    listed_tensors = []\n",
    "    for i in list_of_paths:\n",
    "        listed_tensors.append(stacked_tensors(i))\n",
    "    squashed_tensors = torch.cat(listed_tensors).view(-1, 28*28)\n",
    "    return squashed_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36fff3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_tensors(list_of_paths):\n",
    "    squashed_tensors = torch.cat([stacked_tensors(o) for o in list_of_paths]).view(-1, 28*28)\n",
    "    return squashed_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a02dae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the squashed tensors are equal\n",
    "squashed_threes_and_sevens = squash_tensors([sorted_training_folder[3], sorted_training_folder[7]])\n",
    "\n",
    "squashed_threes_and_sevens.shape == test_tensor.shape, torch.equal(squashed_threes_and_sevens, test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a08522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squashed_training_tensors = squash_tensors(sorted_training_folder)\n",
    "\n",
    "squashed_training_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d2ad690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]),\n",
       " torch.Size([1028, 28, 28]),\n",
       " torch.Size([2038, 784]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid3s_tensor = torch.stack([tensor(Image.open(o)) for o in (sorted_testing_folder[3]).ls().sorted()]).float()/255\n",
    "valid7s_tensor = torch.stack([tensor(Image.open(o)) for o in (sorted_testing_folder[7]).ls().sorted()]).float()/255\n",
    "valid37s_tensor = torch.cat([valid3s_tensor, valid7s_tensor]).view(-1, 28*28)\n",
    "\n",
    "valid3s_tensor.shape, valid7s_tensor.shape, valid37s_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e639bd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]),\n",
       " torch.Size([1028, 28, 28]),\n",
       " torch.Size([2038, 784]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_stacked_threes = stacked_tensors(sorted_testing_folder[3])\n",
    "validation_stacked_sevens = stacked_tensors(sorted_testing_folder[7])\n",
    "squashed_valid3and7s_tensor = squash_tensors([sorted_testing_folder[3], sorted_testing_folder[7]])\n",
    "\n",
    "validation_stacked_threes.shape, validation_stacked_sevens.shape, squashed_valid3and7s_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b060be6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensors are equal.\n"
     ]
    }
   ],
   "source": [
    "#Corroborate equality of stacked tensors\n",
    "if torch.equal(valid3s_tensor, validation_stacked_threes) and torch.equal(valid7s_tensor, validation_stacked_sevens) :\n",
    "    print(\"The tensors are equal.\")\n",
    "else:\n",
    "    print(\"The tensors are not equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73319112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the squashed tensors are equal\n",
    "squashed_valid3and7s_tensor.shape == valid37s_tensor.shape, torch.equal(squashed_valid3and7s_tensor, valid37s_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e660b681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squashed_validation_tensors = squash_tensors(sorted_testing_folder)\n",
    "\n",
    "squashed_validation_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d96920b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test = tensor([1]*len(threes_tensors) + [0]*len(sevens_tensors)).unsqueeze(1)\n",
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bf63ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the validation labels tensor\n",
    "def getlabels(folders):\n",
    "    list_of_labels = []\n",
    "    for o in range(len(folders)):\n",
    "        list_of_labels = list_of_labels + [o]*len(folders[o].ls())\n",
    "    labels_tensor = tensor(list_of_labels)\n",
    "    return labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d693c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension version of the code block above\n",
    "#start_time = time.time()\n",
    "#a = [o for o in range(len(sorted_testing_folder)) for _ in range(len(sorted_testing_folder[o].ls()))]\n",
    "#tensor_a = torch.tensor(a)\n",
    "#for_loop_time = time.time() - start_time\n",
    "#for_loop_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "116ea797",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels_tensor = getlabels(sorted_testing_folder)\n",
    "\n",
    "training_labels_tensor = getlabels(sorted_training_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4861b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = list(zip(squashed_validation_tensors, validation_labels_tensor))\n",
    "\n",
    "training_dataset = list(zip(squashed_training_tensors, training_labels_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57cb3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataloader = DataLoader(validation_dataset, batch_size = 64)\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38cc0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": training_dataloader,\n",
    "    \"validation\": validation_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c910108",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10),\n",
    "    nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7af816e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nb_epoch is our number of epochs, meaning the number of complete passes through the training dataset.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 1e-2\n",
    "nb_epoch = 350\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a8ac2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(pytorch_net.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2c92698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
    "    #liveloss = PlotLosses() Live training plot generic API\n",
    "    epochno = 0\n",
    "    model = model.to(device) # Moves and/or casts the parameters and buffers to device.\n",
    "    \n",
    "    for epoch in range(num_epochs): # Number of passes through the entire training & validation datasets\n",
    "        logs = {}\n",
    "        for phase in ['train', 'validation']: # First train, then validate\n",
    "            if phase == 'train':\n",
    "                model.train() # Set the module in training mode\n",
    "            else:\n",
    "                model.eval() # Set the module in evaluation mode\n",
    "\n",
    "            running_loss = 0.0 # keep track of loss\n",
    "            running_corrects = 0 # count of carrectly classified inputs\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device) # Perform Tensor device conversion\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs) # forward pass through network\n",
    "                loss = criterion(outputs, labels) # Calculate loss\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad() # Set all previously calculated gradients to 0\n",
    "                    loss.backward() # Calculate gradients\n",
    "                    optimizer.step() # Step on the weights using those gradient w -=  gradient(w) * lr\n",
    "\n",
    "                _, preds = torch.max(outputs, 1) # Get model's predictions\n",
    "                running_loss += loss.detach() * inputs.size(0) # multiply mean loss by the number of elements\n",
    "                running_corrects += torch.sum(preds == labels.data) # add number of correct predictions to total\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset) # get the \"mean\" loss for the epoch\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset) # Get proportion of correct predictions\n",
    "            \n",
    "            # Logging\n",
    "            prefix = ''\n",
    "            if phase == 'validation':\n",
    "                prefix = 'val_'\n",
    "\n",
    "            logs[prefix + 'log loss'] = epoch_loss.item()\n",
    "            logs[prefix + 'accuracy'] = epoch_acc.item()\n",
    "        print('Epoch: ', epochno,' loss: ', epoch_loss.item(), ' accuracy: ', epoch_acc.item())\n",
    "        epochno += 1\n",
    "        #liveloss.update(logs) Update logs\n",
    "        #liveloss.send()  draw, display stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1f2e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  loss:  0.3403874337673187  accuracy:  0.9575999975204468\n",
      "Epoch:  1  loss:  0.3400493264198303  accuracy:  0.9575999975204468\n",
      "Epoch:  2  loss:  0.33953434228897095  accuracy:  0.9578999876976013\n",
      "Epoch:  3  loss:  0.33907467126846313  accuracy:  0.9580999612808228\n",
      "Epoch:  4  loss:  0.3386257588863373  accuracy:  0.958299994468689\n",
      "Epoch:  5  loss:  0.33813780546188354  accuracy:  0.9583999514579773\n",
      "Epoch:  6  loss:  0.3379271328449249  accuracy:  0.9584999680519104\n",
      "Epoch:  7  loss:  0.33726394176483154  accuracy:  0.9587999582290649\n",
      "Epoch:  8  loss:  0.33691543340682983  accuracy:  0.9589999914169312\n",
      "Epoch:  9  loss:  0.33650073409080505  accuracy:  0.9592999815940857\n",
      "Epoch:  10  loss:  0.3360438346862793  accuracy:  0.9594999551773071\n",
      "Epoch:  11  loss:  0.335604190826416  accuracy:  0.9596999883651733\n",
      "Epoch:  12  loss:  0.33526766300201416  accuracy:  0.9598999619483948\n",
      "Epoch:  13  loss:  0.33480918407440186  accuracy:  0.9598999619483948\n",
      "Epoch:  14  loss:  0.33429884910583496  accuracy:  0.9599999785423279\n",
      "Epoch:  15  loss:  0.33378395438194275  accuracy:  0.960099995136261\n",
      "Epoch:  16  loss:  0.3335649371147156  accuracy:  0.960099995136261\n",
      "Epoch:  17  loss:  0.3330481946468353  accuracy:  0.960099995136261\n",
      "Epoch:  18  loss:  0.3324677050113678  accuracy:  0.9601999521255493\n",
      "Epoch:  19  loss:  0.33210986852645874  accuracy:  0.9601999521255493\n",
      "Epoch:  20  loss:  0.33168020844459534  accuracy:  0.9601999521255493\n",
      "Epoch:  21  loss:  0.33127859234809875  accuracy:  0.9601999521255493\n",
      "Epoch:  22  loss:  0.3307133615016937  accuracy:  0.9602999687194824\n",
      "Epoch:  23  loss:  0.3303559124469757  accuracy:  0.9602999687194824\n",
      "Epoch:  24  loss:  0.329936683177948  accuracy:  0.9602999687194824\n",
      "Epoch:  25  loss:  0.32946279644966125  accuracy:  0.9605000019073486\n",
      "Epoch:  26  loss:  0.32913854718208313  accuracy:  0.960599958896637\n",
      "Epoch:  27  loss:  0.3286420702934265  accuracy:  0.9606999754905701\n",
      "Epoch:  28  loss:  0.3282383382320404  accuracy:  0.960599958896637\n",
      "Epoch:  29  loss:  0.3278278112411499  accuracy:  0.9606999754905701\n",
      "Epoch:  30  loss:  0.3272562623023987  accuracy:  0.9603999853134155\n",
      "Epoch:  31  loss:  0.3269455134868622  accuracy:  0.960599958896637\n",
      "Epoch:  32  loss:  0.32635682821273804  accuracy:  0.9603999853134155\n",
      "Epoch:  33  loss:  0.32610949873924255  accuracy:  0.9605000019073486\n",
      "Epoch:  34  loss:  0.3255205750465393  accuracy:  0.9605000019073486\n",
      "Epoch:  35  loss:  0.32508984208106995  accuracy:  0.9605000019073486\n",
      "Epoch:  36  loss:  0.32468247413635254  accuracy:  0.960599958896637\n",
      "Epoch:  37  loss:  0.3240671753883362  accuracy:  0.9606999754905701\n",
      "Epoch:  38  loss:  0.3236076235771179  accuracy:  0.9606999754905701\n",
      "Epoch:  39  loss:  0.32322239875793457  accuracy:  0.9607999920845032\n",
      "Epoch:  40  loss:  0.322740763425827  accuracy:  0.9609999656677246\n",
      "Epoch:  41  loss:  0.32215946912765503  accuracy:  0.9610999822616577\n",
      "Epoch:  42  loss:  0.321791410446167  accuracy:  0.9611999988555908\n",
      "Epoch:  43  loss:  0.3213821351528168  accuracy:  0.9613999724388123\n",
      "Epoch:  44  loss:  0.320923388004303  accuracy:  0.9614999890327454\n",
      "Epoch:  45  loss:  0.32061758637428284  accuracy:  0.9614999890327454\n",
      "Epoch:  46  loss:  0.320081889629364  accuracy:  0.9616999626159668\n",
      "Epoch:  47  loss:  0.3197697103023529  accuracy:  0.9617999792098999\n",
      "Epoch:  48  loss:  0.3192198872566223  accuracy:  0.9617999792098999\n",
      "Epoch:  49  loss:  0.31882691383361816  accuracy:  0.9616999626159668\n",
      "Epoch:  50  loss:  0.3184162378311157  accuracy:  0.9621999859809875\n",
      "Epoch:  51  loss:  0.3181045949459076  accuracy:  0.9623000025749207\n",
      "Epoch:  52  loss:  0.31753602623939514  accuracy:  0.962399959564209\n",
      "Epoch:  53  loss:  0.31724995374679565  accuracy:  0.962399959564209\n",
      "Epoch:  54  loss:  0.31683290004730225  accuracy:  0.9624999761581421\n",
      "Epoch:  55  loss:  0.31634825468063354  accuracy:  0.9624999761581421\n",
      "Epoch:  56  loss:  0.31596842408180237  accuracy:  0.9625999927520752\n",
      "Epoch:  57  loss:  0.3155476450920105  accuracy:  0.9624999761581421\n",
      "Epoch:  58  loss:  0.31520986557006836  accuracy:  0.9624999761581421\n",
      "Epoch:  59  loss:  0.3147181272506714  accuracy:  0.9624999761581421\n",
      "Epoch:  60  loss:  0.314375102519989  accuracy:  0.9624999761581421\n",
      "Epoch:  61  loss:  0.3139841854572296  accuracy:  0.9624999761581421\n",
      "Epoch:  62  loss:  0.31347328424453735  accuracy:  0.9625999927520752\n",
      "Epoch:  63  loss:  0.3131980001926422  accuracy:  0.9624999761581421\n",
      "Epoch:  64  loss:  0.31274768710136414  accuracy:  0.962399959564209\n",
      "Epoch:  65  loss:  0.31238284707069397  accuracy:  0.9625999927520752\n",
      "Epoch:  66  loss:  0.31199023127555847  accuracy:  0.9626999497413635\n",
      "Epoch:  67  loss:  0.31161072850227356  accuracy:  0.9629999995231628\n",
      "Epoch:  68  loss:  0.3112024664878845  accuracy:  0.9630999565124512\n",
      "Epoch:  69  loss:  0.31078699231147766  accuracy:  0.9632999897003174\n",
      "Epoch:  70  loss:  0.31045979261398315  accuracy:  0.9631999731063843\n",
      "Epoch:  71  loss:  0.3100050091743469  accuracy:  0.9632999897003174\n",
      "Epoch:  72  loss:  0.3096882104873657  accuracy:  0.9632999897003174\n",
      "Epoch:  73  loss:  0.3092736601829529  accuracy:  0.9631999731063843\n",
      "Epoch:  74  loss:  0.30884459614753723  accuracy:  0.9634999632835388\n",
      "Epoch:  75  loss:  0.308498740196228  accuracy:  0.9633999466896057\n",
      "Epoch:  76  loss:  0.30809858441352844  accuracy:  0.9634999632835388\n",
      "Epoch:  77  loss:  0.30775612592697144  accuracy:  0.9633999466896057\n",
      "Epoch:  78  loss:  0.3073180615901947  accuracy:  0.9634999632835388\n",
      "Epoch:  79  loss:  0.30703189969062805  accuracy:  0.9634999632835388\n",
      "Epoch:  80  loss:  0.3065965473651886  accuracy:  0.9637999534606934\n",
      "Epoch:  81  loss:  0.30615365505218506  accuracy:  0.9635999798774719\n",
      "Epoch:  82  loss:  0.3058936893939972  accuracy:  0.9635999798774719\n",
      "Epoch:  83  loss:  0.30547112226486206  accuracy:  0.963699996471405\n",
      "Epoch:  84  loss:  0.30510610342025757  accuracy:  0.9635999798774719\n",
      "Epoch:  85  loss:  0.3047046959400177  accuracy:  0.963699996471405\n",
      "Epoch:  86  loss:  0.3044419586658478  accuracy:  0.9638999700546265\n",
      "Epoch:  87  loss:  0.3040502667427063  accuracy:  0.9639999866485596\n",
      "Epoch:  88  loss:  0.3036234676837921  accuracy:  0.9641000032424927\n",
      "Epoch:  89  loss:  0.30327731370925903  accuracy:  0.9641000032424927\n",
      "Epoch:  90  loss:  0.30285781621932983  accuracy:  0.9641000032424927\n",
      "Epoch:  91  loss:  0.3026150166988373  accuracy:  0.9639999866485596\n",
      "Epoch:  92  loss:  0.3021656572818756  accuracy:  0.9639999866485596\n",
      "Epoch:  93  loss:  0.30189645290374756  accuracy:  0.9639999866485596\n",
      "Epoch:  94  loss:  0.3015166223049164  accuracy:  0.9639999866485596\n",
      "Epoch:  95  loss:  0.3011000454425812  accuracy:  0.9641000032424927\n",
      "Epoch:  96  loss:  0.3008633255958557  accuracy:  0.964199960231781\n",
      "Epoch:  97  loss:  0.3004913628101349  accuracy:  0.9643999934196472\n",
      "Epoch:  98  loss:  0.3001886010169983  accuracy:  0.9644999504089355\n",
      "Epoch:  99  loss:  0.2998535931110382  accuracy:  0.9645999670028687\n",
      "Epoch:  100  loss:  0.29946497082710266  accuracy:  0.9645999670028687\n",
      "Epoch:  101  loss:  0.29916730523109436  accuracy:  0.9646999835968018\n",
      "Epoch:  102  loss:  0.298849880695343  accuracy:  0.9648999571800232\n",
      "Epoch:  103  loss:  0.29853352904319763  accuracy:  0.9648999571800232\n",
      "Epoch:  104  loss:  0.2982396185398102  accuracy:  0.9648999571800232\n",
      "Epoch:  105  loss:  0.2978522479534149  accuracy:  0.9648999571800232\n",
      "Epoch:  106  loss:  0.29758840799331665  accuracy:  0.9649999737739563\n",
      "Epoch:  107  loss:  0.2971964180469513  accuracy:  0.9649999737739563\n",
      "Epoch:  108  loss:  0.2969050407409668  accuracy:  0.9649999737739563\n",
      "Epoch:  109  loss:  0.2965863049030304  accuracy:  0.9649999737739563\n",
      "Epoch:  110  loss:  0.2962018847465515  accuracy:  0.9649999737739563\n",
      "Epoch:  111  loss:  0.29596760869026184  accuracy:  0.9649999737739563\n",
      "Epoch:  112  loss:  0.29560327529907227  accuracy:  0.9650999903678894\n",
      "Epoch:  113  loss:  0.2953146994113922  accuracy:  0.9648999571800232\n",
      "Epoch:  114  loss:  0.29504305124282837  accuracy:  0.9649999737739563\n",
      "Epoch:  115  loss:  0.2947649359703064  accuracy:  0.9650999903678894\n",
      "Epoch:  116  loss:  0.29434940218925476  accuracy:  0.9651999473571777\n",
      "Epoch:  117  loss:  0.29414957761764526  accuracy:  0.9651999473571777\n",
      "Epoch:  118  loss:  0.2938257157802582  accuracy:  0.9651999473571777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  119  loss:  0.29350635409355164  accuracy:  0.9651999473571777\n",
      "Epoch:  120  loss:  0.29326945543289185  accuracy:  0.9651999473571777\n",
      "Epoch:  121  loss:  0.29291021823883057  accuracy:  0.965499997138977\n",
      "Epoch:  122  loss:  0.292670339345932  accuracy:  0.9655999541282654\n",
      "Epoch:  123  loss:  0.2923286259174347  accuracy:  0.9655999541282654\n",
      "Epoch:  124  loss:  0.2920197546482086  accuracy:  0.9656999707221985\n",
      "Epoch:  125  loss:  0.29180195927619934  accuracy:  0.9657999873161316\n",
      "Epoch:  126  loss:  0.29140743613243103  accuracy:  0.9657999873161316\n",
      "Epoch:  127  loss:  0.29115474224090576  accuracy:  0.9659000039100647\n",
      "Epoch:  128  loss:  0.2909398376941681  accuracy:  0.9659000039100647\n",
      "Epoch:  129  loss:  0.29059022665023804  accuracy:  0.9659000039100647\n",
      "Epoch:  130  loss:  0.2902918756008148  accuracy:  0.9659000039100647\n",
      "Epoch:  131  loss:  0.2900579571723938  accuracy:  0.9659000039100647\n",
      "Epoch:  132  loss:  0.2897524833679199  accuracy:  0.9656999707221985\n",
      "Epoch:  133  loss:  0.28945836424827576  accuracy:  0.9656999707221985\n",
      "Epoch:  134  loss:  0.2892393469810486  accuracy:  0.9656999707221985\n",
      "Epoch:  135  loss:  0.2889249622821808  accuracy:  0.965999960899353\n",
      "Epoch:  136  loss:  0.28863877058029175  accuracy:  0.9660999774932861\n",
      "Epoch:  137  loss:  0.2883809506893158  accuracy:  0.9660999774932861\n",
      "Epoch:  138  loss:  0.2880866229534149  accuracy:  0.9663999676704407\n",
      "Epoch:  139  loss:  0.28787127137184143  accuracy:  0.9663999676704407\n",
      "Epoch:  140  loss:  0.28760796785354614  accuracy:  0.9663999676704407\n",
      "Epoch:  141  loss:  0.2872825860977173  accuracy:  0.9666000008583069\n",
      "Epoch:  142  loss:  0.28707143664360046  accuracy:  0.9664999842643738\n",
      "Epoch:  143  loss:  0.28679484128952026  accuracy:  0.9664999842643738\n",
      "Epoch:  144  loss:  0.2865719497203827  accuracy:  0.9666999578475952\n",
      "Epoch:  145  loss:  0.2863055467605591  accuracy:  0.9666000008583069\n",
      "Epoch:  146  loss:  0.286023885011673  accuracy:  0.9667999744415283\n",
      "Epoch:  147  loss:  0.28583988547325134  accuracy:  0.9667999744415283\n",
      "Epoch:  148  loss:  0.28554850816726685  accuracy:  0.9667999744415283\n",
      "Epoch:  149  loss:  0.28528907895088196  accuracy:  0.9667999744415283\n",
      "Epoch:  150  loss:  0.28503137826919556  accuracy:  0.9667999744415283\n",
      "Epoch:  151  loss:  0.2848045825958252  accuracy:  0.9667999744415283\n",
      "Epoch:  152  loss:  0.28453725576400757  accuracy:  0.9667999744415283\n",
      "Epoch:  153  loss:  0.28436151146888733  accuracy:  0.9668999910354614\n",
      "Epoch:  154  loss:  0.28403240442276  accuracy:  0.9667999744415283\n",
      "Epoch:  155  loss:  0.2838778495788574  accuracy:  0.9667999744415283\n",
      "Epoch:  156  loss:  0.28363722562789917  accuracy:  0.9667999744415283\n",
      "Epoch:  157  loss:  0.2833434045314789  accuracy:  0.9667999744415283\n",
      "Epoch:  158  loss:  0.28317752480506897  accuracy:  0.9667999744415283\n",
      "Epoch:  159  loss:  0.28290823101997375  accuracy:  0.9667999744415283\n",
      "Epoch:  160  loss:  0.2826665937900543  accuracy:  0.9667999744415283\n",
      "Epoch:  161  loss:  0.2824649214744568  accuracy:  0.9668999910354614\n",
      "Epoch:  162  loss:  0.28223732113838196  accuracy:  0.9669999480247498\n",
      "Epoch:  163  loss:  0.2819902002811432  accuracy:  0.9669999480247498\n",
      "Epoch:  164  loss:  0.28181079030036926  accuracy:  0.9669999480247498\n",
      "Epoch:  165  loss:  0.2815995514392853  accuracy:  0.9668999910354614\n",
      "Epoch:  166  loss:  0.28132131695747375  accuracy:  0.9669999480247498\n",
      "Epoch:  167  loss:  0.28112542629241943  accuracy:  0.9669999480247498\n",
      "Epoch:  168  loss:  0.2809487581253052  accuracy:  0.9668999910354614\n",
      "Epoch:  169  loss:  0.28066501021385193  accuracy:  0.9672999978065491\n",
      "Epoch:  170  loss:  0.2804631292819977  accuracy:  0.967199981212616\n",
      "Epoch:  171  loss:  0.2802880108356476  accuracy:  0.967199981212616\n",
      "Epoch:  172  loss:  0.28005534410476685  accuracy:  0.9673999547958374\n",
      "Epoch:  173  loss:  0.27983495593070984  accuracy:  0.9675999879837036\n",
      "Epoch:  174  loss:  0.2796667516231537  accuracy:  0.9675999879837036\n",
      "Epoch:  175  loss:  0.27942222356796265  accuracy:  0.9675999879837036\n",
      "Epoch:  176  loss:  0.27926743030548096  accuracy:  0.9675999879837036\n",
      "Epoch:  177  loss:  0.278997540473938  accuracy:  0.9675999879837036\n",
      "Epoch:  178  loss:  0.27883195877075195  accuracy:  0.9675999879837036\n",
      "Epoch:  179  loss:  0.2786518931388855  accuracy:  0.9677000045776367\n",
      "Epoch:  180  loss:  0.2784045934677124  accuracy:  0.9677000045776367\n",
      "Epoch:  181  loss:  0.2782086133956909  accuracy:  0.9677000045776367\n",
      "Epoch:  182  loss:  0.2780279815196991  accuracy:  0.9675999879837036\n",
      "Epoch:  183  loss:  0.2778492271900177  accuracy:  0.9675999879837036\n",
      "Epoch:  184  loss:  0.27759045362472534  accuracy:  0.9675999879837036\n",
      "Epoch:  185  loss:  0.27747517824172974  accuracy:  0.9675999879837036\n",
      "Epoch:  186  loss:  0.2772238850593567  accuracy:  0.9674999713897705\n",
      "Epoch:  187  loss:  0.2770324647426605  accuracy:  0.9674999713897705\n",
      "Epoch:  188  loss:  0.27691471576690674  accuracy:  0.9674999713897705\n",
      "Epoch:  189  loss:  0.27670255303382874  accuracy:  0.9673999547958374\n",
      "Epoch:  190  loss:  0.27647319436073303  accuracy:  0.9675999879837036\n",
      "Epoch:  191  loss:  0.2763194143772125  accuracy:  0.9675999879837036\n",
      "Epoch:  192  loss:  0.27613335847854614  accuracy:  0.9675999879837036\n",
      "Epoch:  193  loss:  0.27594903111457825  accuracy:  0.9674999713897705\n",
      "Epoch:  194  loss:  0.2757846415042877  accuracy:  0.9675999879837036\n",
      "Epoch:  195  loss:  0.27564379572868347  accuracy:  0.9675999879837036\n",
      "Epoch:  196  loss:  0.2754043638706207  accuracy:  0.9675999879837036\n",
      "Epoch:  197  loss:  0.27526476979255676  accuracy:  0.9675999879837036\n",
      "Epoch:  198  loss:  0.27509239315986633  accuracy:  0.9675999879837036\n",
      "Epoch:  199  loss:  0.27493125200271606  accuracy:  0.9678999781608582\n",
      "Epoch:  200  loss:  0.2747752070426941  accuracy:  0.967799961566925\n",
      "Epoch:  201  loss:  0.27459022402763367  accuracy:  0.9680999517440796\n",
      "Epoch:  202  loss:  0.27441754937171936  accuracy:  0.9680999517440796\n",
      "Epoch:  203  loss:  0.2742587924003601  accuracy:  0.9680999517440796\n",
      "Epoch:  204  loss:  0.27410101890563965  accuracy:  0.9680999517440796\n",
      "Epoch:  205  loss:  0.27391666173934937  accuracy:  0.9680999517440796\n",
      "Epoch:  206  loss:  0.27377381920814514  accuracy:  0.9680999517440796\n",
      "Epoch:  207  loss:  0.2736133933067322  accuracy:  0.9680999517440796\n",
      "Epoch:  208  loss:  0.27342960238456726  accuracy:  0.9681999683380127\n",
      "Epoch:  209  loss:  0.2732977867126465  accuracy:  0.9681999683380127\n",
      "Epoch:  210  loss:  0.27313652634620667  accuracy:  0.9681999683380127\n",
      "Epoch:  211  loss:  0.2729796767234802  accuracy:  0.9681999683380127\n",
      "Epoch:  212  loss:  0.2728649973869324  accuracy:  0.9681999683380127\n",
      "Epoch:  213  loss:  0.27266037464141846  accuracy:  0.9680999517440796\n",
      "Epoch:  214  loss:  0.2725280523300171  accuracy:  0.9680999517440796\n",
      "Epoch:  215  loss:  0.2723461389541626  accuracy:  0.9680999517440796\n",
      "Epoch:  216  loss:  0.2722180187702179  accuracy:  0.9680999517440796\n",
      "Epoch:  217  loss:  0.27205175161361694  accuracy:  0.9680999517440796\n",
      "Epoch:  218  loss:  0.2718799412250519  accuracy:  0.9680999517440796\n",
      "Epoch:  219  loss:  0.27176621556282043  accuracy:  0.9681999683380127\n",
      "Epoch:  220  loss:  0.27163460850715637  accuracy:  0.9682999849319458\n",
      "Epoch:  221  loss:  0.2714633643627167  accuracy:  0.9684000015258789\n",
      "Epoch:  222  loss:  0.2713354527950287  accuracy:  0.9684999585151672\n",
      "Epoch:  223  loss:  0.2711966931819916  accuracy:  0.9684999585151672\n",
      "Epoch:  224  loss:  0.27101460099220276  accuracy:  0.9685999751091003\n",
      "Epoch:  225  loss:  0.27094265818595886  accuracy:  0.9684999585151672\n",
      "Epoch:  226  loss:  0.27079570293426514  accuracy:  0.9685999751091003\n",
      "Epoch:  227  loss:  0.27061596512794495  accuracy:  0.9686999917030334\n",
      "Epoch:  228  loss:  0.27053946256637573  accuracy:  0.9685999751091003\n",
      "Epoch:  229  loss:  0.2703831195831299  accuracy:  0.9686999917030334\n",
      "Epoch:  230  loss:  0.27023300528526306  accuracy:  0.9686999917030334\n",
      "Epoch:  231  loss:  0.2701638340950012  accuracy:  0.9687999486923218\n",
      "Epoch:  232  loss:  0.2700180411338806  accuracy:  0.9686999917030334\n",
      "Epoch:  233  loss:  0.26984748244285583  accuracy:  0.9687999486923218\n",
      "Epoch:  234  loss:  0.26977282762527466  accuracy:  0.9686999917030334\n",
      "Epoch:  235  loss:  0.26961517333984375  accuracy:  0.9686999917030334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  236  loss:  0.26950564980506897  accuracy:  0.9686999917030334\n",
      "Epoch:  237  loss:  0.2693679928779602  accuracy:  0.9687999486923218\n",
      "Epoch:  238  loss:  0.2692415714263916  accuracy:  0.9687999486923218\n",
      "Epoch:  239  loss:  0.26915696263313293  accuracy:  0.968999981880188\n",
      "Epoch:  240  loss:  0.26903390884399414  accuracy:  0.968999981880188\n",
      "Epoch:  241  loss:  0.2688800096511841  accuracy:  0.9688999652862549\n",
      "Epoch:  242  loss:  0.26880741119384766  accuracy:  0.9688999652862549\n",
      "Epoch:  243  loss:  0.26865869760513306  accuracy:  0.968999981880188\n",
      "Epoch:  244  loss:  0.268553227186203  accuracy:  0.968999981880188\n",
      "Epoch:  245  loss:  0.268454372882843  accuracy:  0.968999981880188\n",
      "Epoch:  246  loss:  0.2683180570602417  accuracy:  0.968999981880188\n",
      "Epoch:  247  loss:  0.268179714679718  accuracy:  0.968999981880188\n",
      "Epoch:  248  loss:  0.26808223128318787  accuracy:  0.968999981880188\n",
      "Epoch:  249  loss:  0.2679423391819  accuracy:  0.968999981880188\n",
      "Epoch:  250  loss:  0.2678338587284088  accuracy:  0.968999981880188\n",
      "Epoch:  251  loss:  0.2677222192287445  accuracy:  0.968999981880188\n",
      "Epoch:  252  loss:  0.2675951421260834  accuracy:  0.968999981880188\n",
      "Epoch:  253  loss:  0.2675088346004486  accuracy:  0.968999981880188\n",
      "Epoch:  254  loss:  0.2674012780189514  accuracy:  0.968999981880188\n",
      "Epoch:  255  loss:  0.2672872543334961  accuracy:  0.968999981880188\n",
      "Epoch:  256  loss:  0.2671903967857361  accuracy:  0.968999981880188\n",
      "Epoch:  257  loss:  0.26708054542541504  accuracy:  0.968999981880188\n",
      "Epoch:  258  loss:  0.26698023080825806  accuracy:  0.9690999984741211\n",
      "Epoch:  259  loss:  0.2669024169445038  accuracy:  0.9690999984741211\n",
      "Epoch:  260  loss:  0.26677003502845764  accuracy:  0.9690999984741211\n",
      "Epoch:  261  loss:  0.26669973134994507  accuracy:  0.9691999554634094\n",
      "Epoch:  262  loss:  0.2665976285934448  accuracy:  0.9691999554634094\n",
      "Epoch:  263  loss:  0.2665221393108368  accuracy:  0.9691999554634094\n",
      "Epoch:  264  loss:  0.26642483472824097  accuracy:  0.9690999984741211\n",
      "Epoch:  265  loss:  0.26632601022720337  accuracy:  0.968999981880188\n",
      "Epoch:  266  loss:  0.26623663306236267  accuracy:  0.968999981880188\n",
      "Epoch:  267  loss:  0.26612943410873413  accuracy:  0.9688999652862549\n",
      "Epoch:  268  loss:  0.26606836915016174  accuracy:  0.9687999486923218\n",
      "Epoch:  269  loss:  0.265971302986145  accuracy:  0.9690999984741211\n",
      "Epoch:  270  loss:  0.26587823033332825  accuracy:  0.9690999984741211\n",
      "Epoch:  271  loss:  0.2658086121082306  accuracy:  0.9691999554634094\n",
      "Epoch:  272  loss:  0.2657061517238617  accuracy:  0.9691999554634094\n",
      "Epoch:  273  loss:  0.26564136147499084  accuracy:  0.9692999720573425\n",
      "Epoch:  274  loss:  0.2655646800994873  accuracy:  0.9692999720573425\n",
      "Epoch:  275  loss:  0.2654564678668976  accuracy:  0.9692999720573425\n",
      "Epoch:  276  loss:  0.26539358496665955  accuracy:  0.9692999720573425\n",
      "Epoch:  277  loss:  0.2652825713157654  accuracy:  0.9692999720573425\n",
      "Epoch:  278  loss:  0.2652212679386139  accuracy:  0.9692999720573425\n",
      "Epoch:  279  loss:  0.2651270031929016  accuracy:  0.9692999720573425\n",
      "Epoch:  280  loss:  0.2650550603866577  accuracy:  0.9692999720573425\n",
      "Epoch:  281  loss:  0.2649919390678406  accuracy:  0.9692999720573425\n",
      "Epoch:  282  loss:  0.26489943265914917  accuracy:  0.9692999720573425\n",
      "Epoch:  283  loss:  0.2648411691188812  accuracy:  0.9692999720573425\n",
      "Epoch:  284  loss:  0.2647422254085541  accuracy:  0.9692999720573425\n",
      "Epoch:  285  loss:  0.2646639347076416  accuracy:  0.9693999886512756\n",
      "Epoch:  286  loss:  0.2645859122276306  accuracy:  0.9693999886512756\n",
      "Epoch:  287  loss:  0.26450884342193604  accuracy:  0.9693999886512756\n",
      "Epoch:  288  loss:  0.2644409239292145  accuracy:  0.9695000052452087\n",
      "Epoch:  289  loss:  0.26439395546913147  accuracy:  0.9695000052452087\n",
      "Epoch:  290  loss:  0.2642841637134552  accuracy:  0.9695000052452087\n",
      "Epoch:  291  loss:  0.26423028111457825  accuracy:  0.9695999622344971\n",
      "Epoch:  292  loss:  0.2641642391681671  accuracy:  0.9695999622344971\n",
      "Epoch:  293  loss:  0.26410457491874695  accuracy:  0.9695999622344971\n",
      "Epoch:  294  loss:  0.2640194892883301  accuracy:  0.9696999788284302\n",
      "Epoch:  295  loss:  0.26394569873809814  accuracy:  0.9697999954223633\n",
      "Epoch:  296  loss:  0.2639026343822479  accuracy:  0.9698999524116516\n",
      "Epoch:  297  loss:  0.2638101875782013  accuracy:  0.9698999524116516\n",
      "Epoch:  298  loss:  0.26376375555992126  accuracy:  0.9698999524116516\n",
      "Epoch:  299  loss:  0.2636881172657013  accuracy:  0.9698999524116516\n",
      "Epoch:  300  loss:  0.26361504197120667  accuracy:  0.9698999524116516\n",
      "Epoch:  301  loss:  0.26355478167533875  accuracy:  0.9698999524116516\n",
      "Epoch:  302  loss:  0.2634741961956024  accuracy:  0.9698999524116516\n",
      "Epoch:  303  loss:  0.2634226083755493  accuracy:  0.9699999690055847\n",
      "Epoch:  304  loss:  0.2633597254753113  accuracy:  0.9700999855995178\n",
      "Epoch:  305  loss:  0.26329004764556885  accuracy:  0.9700999855995178\n",
      "Epoch:  306  loss:  0.2632317543029785  accuracy:  0.9700999855995178\n",
      "Epoch:  307  loss:  0.2631579041481018  accuracy:  0.9702000021934509\n",
      "Epoch:  308  loss:  0.26311904191970825  accuracy:  0.9702000021934509\n",
      "Epoch:  309  loss:  0.26304760575294495  accuracy:  0.9700999855995178\n",
      "Epoch:  310  loss:  0.2629578709602356  accuracy:  0.9700999855995178\n",
      "Epoch:  311  loss:  0.2629353702068329  accuracy:  0.9700999855995178\n",
      "Epoch:  312  loss:  0.26285865902900696  accuracy:  0.9700999855995178\n",
      "Epoch:  313  loss:  0.2628064453601837  accuracy:  0.9700999855995178\n",
      "Epoch:  314  loss:  0.26276811957359314  accuracy:  0.9700999855995178\n",
      "Epoch:  315  loss:  0.262700617313385  accuracy:  0.9700999855995178\n",
      "Epoch:  316  loss:  0.26263922452926636  accuracy:  0.9700999855995178\n",
      "Epoch:  317  loss:  0.26258164644241333  accuracy:  0.9702000021934509\n",
      "Epoch:  318  loss:  0.26254627108573914  accuracy:  0.9702000021934509\n",
      "Epoch:  319  loss:  0.26247429847717285  accuracy:  0.9702000021934509\n",
      "Epoch:  320  loss:  0.2624284327030182  accuracy:  0.9702999591827393\n",
      "Epoch:  321  loss:  0.2623770833015442  accuracy:  0.9702999591827393\n",
      "Epoch:  322  loss:  0.2623254954814911  accuracy:  0.9703999757766724\n",
      "Epoch:  323  loss:  0.2622845470905304  accuracy:  0.9704999923706055\n",
      "Epoch:  324  loss:  0.26223963499069214  accuracy:  0.9704999923706055\n",
      "Epoch:  325  loss:  0.2621947228908539  accuracy:  0.9704999923706055\n",
      "Epoch:  326  loss:  0.2621426582336426  accuracy:  0.9704999923706055\n",
      "Epoch:  327  loss:  0.26207903027534485  accuracy:  0.9704999923706055\n",
      "Epoch:  328  loss:  0.2620560824871063  accuracy:  0.9704999923706055\n",
      "Epoch:  329  loss:  0.26198944449424744  accuracy:  0.9704999923706055\n",
      "Epoch:  330  loss:  0.26196640729904175  accuracy:  0.9704999923706055\n",
      "Epoch:  331  loss:  0.2619147300720215  accuracy:  0.9706999659538269\n",
      "Epoch:  332  loss:  0.2618546485900879  accuracy:  0.9706999659538269\n",
      "Epoch:  333  loss:  0.26182398200035095  accuracy:  0.9706999659538269\n",
      "Epoch:  334  loss:  0.2617800235748291  accuracy:  0.9705999493598938\n",
      "Epoch:  335  loss:  0.26171573996543884  accuracy:  0.9705999493598938\n",
      "Epoch:  336  loss:  0.26170313358306885  accuracy:  0.9705999493598938\n",
      "Epoch:  337  loss:  0.261627197265625  accuracy:  0.9705999493598938\n",
      "Epoch:  338  loss:  0.2615967094898224  accuracy:  0.9705999493598938\n",
      "Epoch:  339  loss:  0.2615503966808319  accuracy:  0.9706999659538269\n",
      "Epoch:  340  loss:  0.2615181505680084  accuracy:  0.9705999493598938\n",
      "Epoch:  341  loss:  0.2614533603191376  accuracy:  0.9705999493598938\n",
      "Epoch:  342  loss:  0.26144683361053467  accuracy:  0.9705999493598938\n",
      "Epoch:  343  loss:  0.26138949394226074  accuracy:  0.9705999493598938\n",
      "Epoch:  344  loss:  0.2613426744937897  accuracy:  0.9706999659538269\n",
      "Epoch:  345  loss:  0.2613159716129303  accuracy:  0.9706999659538269\n",
      "Epoch:  346  loss:  0.26128140091896057  accuracy:  0.9706999659538269\n",
      "Epoch:  347  loss:  0.26121941208839417  accuracy:  0.9706999659538269\n",
      "Epoch:  348  loss:  0.2611984312534332  accuracy:  0.97079998254776\n",
      "Epoch:  349  loss:  0.26115381717681885  accuracy:  0.97079998254776\n"
     ]
    }
   ],
   "source": [
    "train_model(pytorch_net, criterion, optimizer, dataloaders, nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "122744f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pytorch_net, 'models/my_own_dc_97pct.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22139857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3581019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Grayscale(), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize([0.5], [0.5])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4050dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = torchvision.datasets.ImageFolder((training_folder).as_posix(), transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d68ce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f02d8d33bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641affe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f02d8d33e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataset = torchvision.datasets.ImageFolder(testing_folder, transform = transform)\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=batchSize)\n",
    "\n",
    "testing_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db009b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"validation\": testing_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af43c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10),\n",
    "    nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f58720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nb_epoch is our number of epochs, meaning the number of complete passes through the training dataset.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 1e-2\n",
    "nb_epoch = 15\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b9138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(pytorch_net.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2c4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
    "    #liveloss = PlotLosses() Live training plot generic API\n",
    "    model = model.to(device) # Moves and/or casts the parameters and buffers to device.\n",
    "    \n",
    "    for epoch in range(num_epochs): # Number of passes through the entire training & validation datasets\n",
    "        logs = {}\n",
    "        for phase in ['train', 'validation']: # First train, then validate\n",
    "            if phase == 'train':\n",
    "                model.train() # Set the module in training mode\n",
    "            else:\n",
    "                model.eval() # Set the module in evaluation mode\n",
    "\n",
    "            running_loss = 0.0 # keep track of loss\n",
    "            running_corrects = 0 # count of carrectly classified inputs\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device) # Perform Tensor device conversion\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs) # forward pass through network\n",
    "                loss = criterion(outputs, labels) # Calculate loss\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad() # Set all previously calculated gradients to 0\n",
    "                    loss.backward() # Calculate gradients\n",
    "                    optimizer.step() # Step on the weights using those gradient w -=  gradient(w) * lr\n",
    "\n",
    "                _, preds = torch.max(outputs, 1) # Get model's predictions\n",
    "                running_loss += loss.detach() * inputs.size(0) # multiply mean loss by the number of elements\n",
    "                running_corrects += torch.sum(preds == labels.data) # add number of correct predictions to total\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset) # get the \"mean\" loss for the epoch\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset) # Get proportion of correct predictions\n",
    "            \n",
    "            # Logging\n",
    "            prefix = ''\n",
    "            if phase == 'validation':\n",
    "                prefix = 'val_'\n",
    "\n",
    "            logs[prefix + 'log loss'] = epoch_loss.item()\n",
    "            logs[prefix + 'accuracy'] = epoch_acc.item()\n",
    "        print('loss: ', epoch_loss.item(), ' accuracy: ', epoch_acc.item())\n",
    "        \n",
    "        #liveloss.update(logs) Update logs\n",
    "        #liveloss.send()  draw, display stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f790dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.4052080810070038  accuracy:  0.8804000020027161\n",
      "loss:  0.34317728877067566  accuracy:  0.8989999890327454\n",
      "loss:  0.3060593008995056  accuracy:  0.9096999764442444\n",
      "loss:  0.2595570385456085  accuracy:  0.9241999983787537\n",
      "loss:  0.23294584453105927  accuracy:  0.9304999709129333\n",
      "loss:  0.21377748250961304  accuracy:  0.9378999471664429\n",
      "loss:  0.1968572586774826  accuracy:  0.9429000020027161\n",
      "loss:  0.17762190103530884  accuracy:  0.9496999979019165\n",
      "loss:  0.16019994020462036  accuracy:  0.9524999856948853\n",
      "loss:  0.1489601582288742  accuracy:  0.9549999833106995\n",
      "loss:  0.1422155797481537  accuracy:  0.9583999514579773\n",
      "loss:  0.14073260128498077  accuracy:  0.957099974155426\n",
      "loss:  0.15762324631214142  accuracy:  0.949999988079071\n",
      "loss:  0.13402201235294342  accuracy:  0.9598000049591064\n",
      "loss:  0.12043929100036621  accuracy:  0.9657999873161316\n"
     ]
    }
   ],
   "source": [
    "train_model(pytorch_net, criterion, optimizer, dataloaders, nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5bd0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#torch.save(pytorch_net, 'models/my_digit_clasifier_3L_97pct.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379c120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
