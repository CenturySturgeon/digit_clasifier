{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb1712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec4b759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73c9df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d40a1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "094b7b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('../../.fastai/data/mnist_png/testing/5'),\n",
       " Path('../../.fastai/data/mnist_png/testing/3'),\n",
       " Path('../../.fastai/data/mnist_png/testing/7'),\n",
       " Path('../../.fastai/data/mnist_png/testing/4'),\n",
       " Path('../../.fastai/data/mnist_png/testing/2'),\n",
       " Path('../../.fastai/data/mnist_png/testing/1'),\n",
       " Path('../../.fastai/data/mnist_png/testing/9'),\n",
       " Path('../../.fastai/data/mnist_png/testing/0'),\n",
       " Path('../../.fastai/data/mnist_png/testing/8'),\n",
       " Path('../../.fastai/data/mnist_png/testing/6')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_folder = Path('../../.fastai/data/mnist_png/testing')\n",
    "training_folder = Path('../../.fastai/data/mnist_png/training')\n",
    "\n",
    "[x for x in testing_folder.iterdir() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe23efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [Path('../../.fastai/data/mnist_png/testing/0'),Path('../../.fastai/data/mnist_png/testing/1'),Path('../../.fastai/data/mnist_png/testing/2'),Path('../../.fastai/data/mnist_png/testing/3'),Path('../../.fastai/data/mnist_png/testing/4'),Path('../../.fastai/data/mnist_png/testing/5'),Path('../../.fastai/data/mnist_png/testing/6'),Path('../../.fastai/data/mnist_png/testing/7'),Path('../../.fastai/data/mnist_png/testing/8'),Path('../../.fastai/data/mnist_png/testing/9')],\n",
       " (#10) [Path('../../.fastai/data/mnist_png/training/0'),Path('../../.fastai/data/mnist_png/training/1'),Path('../../.fastai/data/mnist_png/training/2'),Path('../../.fastai/data/mnist_png/training/3'),Path('../../.fastai/data/mnist_png/training/4'),Path('../../.fastai/data/mnist_png/training/5'),Path('../../.fastai/data/mnist_png/training/6'),Path('../../.fastai/data/mnist_png/training/7'),Path('../../.fastai/data/mnist_png/training/8'),Path('../../.fastai/data/mnist_png/training/9')])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_testing_folder = testing_folder.ls().sorted()\n",
    "sorted_training_folder = training_folder.ls().sorted()\n",
    "\n",
    "sorted_testing_folder, sorted_training_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3581019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Grayscale(), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize([0.5], [0.5])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4050dba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../../.fastai/data/mnist_png/training\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Grayscale(num_output_channels=1)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5], std=[0.5])\n",
       "           )"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = torchvision.datasets.ImageFolder((training_folder).as_posix(), transform = transform)\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d68ce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa0f9ed0310>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batchSize, shuffle=True)\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641affe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
