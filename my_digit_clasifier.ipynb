{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb1712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4b759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c9df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d40a1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094b7b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('../../.fastai/data/mnist_png/testing/5'),\n",
       " Path('../../.fastai/data/mnist_png/testing/3'),\n",
       " Path('../../.fastai/data/mnist_png/testing/7'),\n",
       " Path('../../.fastai/data/mnist_png/testing/4'),\n",
       " Path('../../.fastai/data/mnist_png/testing/2'),\n",
       " Path('../../.fastai/data/mnist_png/testing/1'),\n",
       " Path('../../.fastai/data/mnist_png/testing/9'),\n",
       " Path('../../.fastai/data/mnist_png/testing/0'),\n",
       " Path('../../.fastai/data/mnist_png/testing/8'),\n",
       " Path('../../.fastai/data/mnist_png/testing/6')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_folder = Path('../../.fastai/data/mnist_png/testing')\n",
    "training_folder = Path('../../.fastai/data/mnist_png/training')\n",
    "\n",
    "[x for x in testing_folder.iterdir() if x.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe23efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#10) [Path('../../.fastai/data/mnist_png/testing/0'),Path('../../.fastai/data/mnist_png/testing/1'),Path('../../.fastai/data/mnist_png/testing/2'),Path('../../.fastai/data/mnist_png/testing/3'),Path('../../.fastai/data/mnist_png/testing/4'),Path('../../.fastai/data/mnist_png/testing/5'),Path('../../.fastai/data/mnist_png/testing/6'),Path('../../.fastai/data/mnist_png/testing/7'),Path('../../.fastai/data/mnist_png/testing/8'),Path('../../.fastai/data/mnist_png/testing/9')],\n",
       " (#10) [Path('../../.fastai/data/mnist_png/training/0'),Path('../../.fastai/data/mnist_png/training/1'),Path('../../.fastai/data/mnist_png/training/2'),Path('../../.fastai/data/mnist_png/training/3'),Path('../../.fastai/data/mnist_png/training/4'),Path('../../.fastai/data/mnist_png/training/5'),Path('../../.fastai/data/mnist_png/training/6'),Path('../../.fastai/data/mnist_png/training/7'),Path('../../.fastai/data/mnist_png/training/8'),Path('../../.fastai/data/mnist_png/training/9')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_testing_folder = testing_folder.ls().sorted()\n",
    "sorted_training_folder = training_folder.ls().sorted()\n",
    "\n",
    "sorted_testing_folder, sorted_training_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3581019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.Grayscale(), torchvision.transforms.ToTensor(), torchvision.transforms.Normalize([0.5], [0.5])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4050dba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../../.fastai/data/mnist_png/training\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Grayscale(num_output_channels=1)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.5], std=[0.5])\n",
       "           )"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset = torchvision.datasets.ImageFolder((training_folder).as_posix(), transform = transform)\n",
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d68ce54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f02d8d33bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchSize = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641affe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f02d8d33e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_dataset = torchvision.datasets.ImageFolder(testing_folder, transform = transform)\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=batchSize)\n",
    "\n",
    "testing_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db009b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    \"train\": train_dataloader,\n",
    "    \"validation\": testing_dataloader\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af43c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,10),\n",
    "    nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f58720c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nb_epoch is our number of epochs, meaning the number of complete passes through the training dataset.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "lr = 1e-2\n",
    "nb_epoch = 15\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b9138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(pytorch_net.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2c4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloaders, num_epochs=10):\n",
    "    #liveloss = PlotLosses() Live training plot generic API\n",
    "    model = model.to(device) # Moves and/or casts the parameters and buffers to device.\n",
    "    \n",
    "    for epoch in range(num_epochs): # Number of passes through the entire training & validation datasets\n",
    "        logs = {}\n",
    "        for phase in ['train', 'validation']: # First train, then validate\n",
    "            if phase == 'train':\n",
    "                model.train() # Set the module in training mode\n",
    "            else:\n",
    "                model.eval() # Set the module in evaluation mode\n",
    "\n",
    "            running_loss = 0.0 # keep track of loss\n",
    "            running_corrects = 0 # count of carrectly classified inputs\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device) # Perform Tensor device conversion\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs) # forward pass through network\n",
    "                loss = criterion(outputs, labels) # Calculate loss\n",
    "\n",
    "                if phase == 'train':\n",
    "                    optimizer.zero_grad() # Set all previously calculated gradients to 0\n",
    "                    loss.backward() # Calculate gradients\n",
    "                    optimizer.step() # Step on the weights using those gradient w -=  gradient(w) * lr\n",
    "\n",
    "                _, preds = torch.max(outputs, 1) # Get model's predictions\n",
    "                running_loss += loss.detach() * inputs.size(0) # multiply mean loss by the number of elements\n",
    "                running_corrects += torch.sum(preds == labels.data) # add number of correct predictions to total\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset) # get the \"mean\" loss for the epoch\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset) # Get proportion of correct predictions\n",
    "            \n",
    "            # Logging\n",
    "            prefix = ''\n",
    "            if phase == 'validation':\n",
    "                prefix = 'val_'\n",
    "\n",
    "            logs[prefix + 'log loss'] = epoch_loss.item()\n",
    "            logs[prefix + 'accuracy'] = epoch_acc.item()\n",
    "        print('loss: ', epoch_loss.item(), ' accuracy: ', epoch_acc.item())\n",
    "        \n",
    "        #liveloss.update(logs) Update logs\n",
    "        #liveloss.send()  draw, display stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f790dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.4052080810070038  accuracy:  0.8804000020027161\n",
      "loss:  0.34317728877067566  accuracy:  0.8989999890327454\n",
      "loss:  0.3060593008995056  accuracy:  0.9096999764442444\n",
      "loss:  0.2595570385456085  accuracy:  0.9241999983787537\n",
      "loss:  0.23294584453105927  accuracy:  0.9304999709129333\n",
      "loss:  0.21377748250961304  accuracy:  0.9378999471664429\n",
      "loss:  0.1968572586774826  accuracy:  0.9429000020027161\n",
      "loss:  0.17762190103530884  accuracy:  0.9496999979019165\n",
      "loss:  0.16019994020462036  accuracy:  0.9524999856948853\n",
      "loss:  0.1489601582288742  accuracy:  0.9549999833106995\n",
      "loss:  0.1422155797481537  accuracy:  0.9583999514579773\n",
      "loss:  0.14073260128498077  accuracy:  0.957099974155426\n",
      "loss:  0.15762324631214142  accuracy:  0.949999988079071\n",
      "loss:  0.13402201235294342  accuracy:  0.9598000049591064\n",
      "loss:  0.12043929100036621  accuracy:  0.9657999873161316\n"
     ]
    }
   ],
   "source": [
    "train_model(pytorch_net, criterion, optimizer, dataloaders, nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5bd0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "#torch.save(pytorch_net, 'models/my_digit_clasifier_3L_97pct.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e379c120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
